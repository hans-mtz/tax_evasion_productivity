

### Testing for the Presence of Tax Evasion Through Overreporting {#sec-tax-ev-test}

@eq-ob-ev suggest a way to test the presence of tax evasion through cost overreporting. Let $\mathbb{E}[\mathcal{V}_{it}]\equiv \mu_{\mathcal{V}}$. Define the null hypothesis as the absence of cost overreporting, $H_0: \mu_{\mathcal{V}}=0$, and the alternative hypothesis as the presence of cost overreporting, $H_1: \mu_{\mathcal{V}}>0$. Consequently, we can use a one-sided t-test to verify for the presence of tax evasion by overreporting.

Under the null hypothesis, there is no tax evasion. Then,
$$
\begin{aligned}  
  z &= \frac{\bar{\mathcal{V}}}{\hat\sigma_{\mathcal{V}}/\sqrt{N}}=\frac{\mathbb{E}[\mathcal{V}]}{\sqrt{\mathbb{Var}[\mathcal{V}]/N}}\\
  &=\frac{-\mathbb{E}[\varepsilon]+\mathbb{E}[e]}{\sqrt{\mathbb{Var}[\varepsilon]+\mathbb{Var}[e]/N}}\\
  &= \frac{-\mathbb{E}[\varepsilon]}{\sqrt{\mathbb{Var}[\varepsilon]/N}}\sim N(0,1)
\end{aligned}
$$

The previous test ignores the sample variance of the $\beta$ estimator in the first stage. 

Alternatively, we can do a difference in means test to account for this variation. This test is equivalent to a two sample GMM test, where in one moment the corporations are used to estimate $\hat\beta$ and the second is a test moment where we use $\hat\beta$ from the first one. Under the null, the two moment should be equal to zero.


Let $s_{it}=log\left(\frac{\rho_t M^*_{it}}{P_t Y_{it}}\right)$ and  $\bar s_G= \frac{1}{N_1T_1}\sum_{i=1}^{N_1}\sum_{t=1}^{T_1}s_{it}^G$ and $\bar s_B= \frac{1}{N_2T_2}\sum_{i=1}^{N_2}\sum_{t=1}^{T_2}s_{it}^B$ be the sample means for good guys (corporations) and the tax evasion guys, respectively. 

Then, the test statistic is,

$$
\begin{aligned}  
  t &= \frac{\bar s_B - \bar s_G}{\sqrt{\hat\sigma^2_{\bar s_B}/N_2T_2 + \hat\sigma^2_{\bar s_G}/N_1T_1}} \sim N(0,1) \text{ under } H_0\\
\end{aligned}
$$

where $\hat\sigma^2_{\bar s_B}$ and $\hat\sigma^2_{\bar s_G}$ are the sample variances of $s_{it}^B$ and $s_{it}^G$, respectively.

Of course, the assumption of independent samples is likely incorrect. For example, firms in an industry might get contemporaneous shocks affecting everyone in one period, like a price shock in inputs. Productivity is usually assumed to be persistent over time, but the effects of productivity of one firm on the other firms is commonly ignored. In addition, if the data uses SIC codes, firms within sub-industries are more likely to be correlated than firms in different sub-industries.


I test for the presence of tax evasion for different classifications of intermediates. Intermediates include raw materials, energy and services. Deductibles include raw materials and deductible expenses. Materials include only raw materials. The items included as deductible expenses or services are detailed in @tbl-expenses-type

```{r}
#| label: tbl-evasion-test-CD
#| tbl-cap: Tax Evasion Through Cost-Overreporting One-Side t-Test by Industry in Colombia. Under the null hypothesis, there is no tax evasion. Values of the statistic were computed from @eq-ob-ev for different intermediate inputs. Standard errors shown in parethesis. Stars indicate significance level at the 1% (\\*\\*\\*), 5% (\\*\\*), and 10% (\\*).

# inds_sales_tax <- tribble(
#     ~ sic_3, ~ Category,
#     311, "1 Exempt Product",
#     312, "1 Exempt Product",
#     382, "1 Exempt Product",
#     383, "1 Exempt Product",
#     384, "1 Exempt Product",
#     369, "1 Exempt Material",
#     323, "1 Exempt Material",
#     356, "3 Specialized Material",
#     322, "4 Direct Customer Sales",
#     324, "4 Direct Customer Sales",
#     342, "4 Direct Customer Sales",
#     369, "4 Direct Customer Sales", 
#     390, "4 Direct Customer Sales"
# )

load("../Code/Products/intermediates.RData")

tax_ev_test_tbl %>%
  # left_join(
  #     top_20_inds
  # ) %>%
  left_join(
      inds_sales_tax
  ) %>%
  filter( sic_3 %in% top_10_ev_inds) %>%
  # mutate(
  #   sic_3 = factor(sic_3,levels=top_10_ev_inds)) %>%
  arrange(Category) %>%
  select(
      sic_3,
      Category,
      # description,
      log_deductible_intermediates_share,
      log_mats_share:log_repair_maint_share
  ) %>%
  kbl(
    col.names = c("SIC", "Category", "Deductibles","Materials", "Electricity", "Fuels", "R&M"),
    table.attr = 'data-quarto-disable-processing="true"'
    ) %>%
    kable_classic(full_width=F, html_font = "Cambria") %>%
    collapse_rows(columns = 1, valign = "top") 
    # pack_rows(
    #   index=c(
    #     "Specialized Material"=1,
    #     "Exempt Product"=5,
    #     "Exempt Material"=2,
    #     "Other Industries"= 12)
    # )

```

```{r}
#| label: tbl-tax-ev-test-context
#| tbl-cap: Tax Evasion Through Cost-Overreporting One-Side t-Test by Industry in Colombia. Under the null hypothesis, there is no tax evasion. Values of the statistic were computed from @eq-ob-ev. Standard errors shown in parethesis. Stars indicate significance level at the 1% (\\*\\*\\*), 5% (\\*\\*), and 10% (\\*).

test_cont_tbl %>%
    mutate(
        across(
            where(is.numeric),
            ~ round(.x, 1)
        ),  
    ) %>% 
    # select(
    #     sic_3, log_mats_share, log_deductible_intermediates_share,
    #     share_sales_tax, sales, materials, share_exports,
    #     share_imports_materials
    # ) %>%
    # filter( sic_3 %in% top_10_ev_inds) %>%
    kbl(
        # col.names = c("SIC", "Materials", "Deductibles", "Sales Tax", "Sales (Mkt %)"," Materials (Mkt %)","Exports","Imports"),
        digits = 2,
        table.attr = 'data-quarto-disable-processing="true"'
    ) %>%
    kable_classic(full_width=F, html_font = "Cambria") %>%
    collapse_rows(columns = 1, valign = "top") 
    # %>%
    # add_header_above(
    #     c(" " = 1, "Test" = 2, "Industry Char." = 5)
    # )


```

@tbl-evasion-test-CD shows that the null hypothesis of no tax evasion is rejected at the 1% significance level for twelve of the top twenty manufacturing industries. 

In particular, there is no evidence of tax evasion for most industries in which products or raw materials are exempt of sales taxes, such as 312 (Other Food Products), 382 (Non-Electrical Machinery), 384 (Transport Equipment), 323 (Leather Products), and 369 (Non-Metallic Mineral Products); there is also no evidence of materials overreporting for 356 (Plastic Products)industry, whose main raw materials are likely to be specialized and supplied by few local and international suppliers.

Among the industries with exempted products, 311 (Food Products) and 383 (Electrical Machinery) there is evidence of tax evasion but as we'll see later the average overreporting is low compared to other industries. 

As expected, the evidence is stronger particularly for the other industries that do not fall in the previous categories. Namely, there is evidence of tax evasion for industries 313 (Beverages); for 321 (Textiles), 322 (Wearing Apparel), and 324 (Footwear); 331 (Wood Products except Furniture) and 332 (Wood Furniture); for industry 341 (Paper) and 342 (Publishing); 351 (Industrial Chemicals) and 352 (Other Chemicals); 381 (Metal Products Except Machinery), and 390 (Other Manufacturing Industries). 


### Deconvoluting Tax Evasion Using Moments

One simple way to start with the deconvolution is using moments. In particular, for every $n$-th moment $\mathbb{E}[\varepsilon_{it}^n|\Theta^{NE}]=\mathbb{E}[\varepsilon_{it}^n|t]=\mathbb{E}[\varepsilon_{it}^n]$

Therefore, any moment of the tax evasion $e_{it}$ distribution $\forall t\in T$ can be estimated in theory.

Namely, from @eq-ob-ev, we can estimate the average tax evasion by
$$
\begin{aligned}
  \mathbb{E}[e_{it}|t]&=\mathbb{E}[\mathcal V_{it}|t]+\mathbb{E}[\varepsilon_{it}]\\
  &=\mathbb{E}[\mathcal V_{it}|t]+\mu_{\varepsilon}
  % \\
  % \mathbb{V}[e_{it}|t]&=\mathbb{V}[\mathcal V_{it}|t]-\mathbb{V}[\varepsilon_{it}]\\
  % &=\mathbb{V}[\mathcal V_{it}|t]-\sigma^2_{\varepsilon}
\end{aligned}
$$

Note that we learned the distribution $f_\varepsilon(\varepsilon)$ of $\varepsilon$ from the first stage, so $\mu_{\varepsilon}$ and $\sigma_{\varepsilon}$ are known.

@tbl-tax-ev-deconv-moments displays the estimated average of the log fraction that firms increase their costs of raw materials to evade taxes by claiming a greater deductible amount of their owed sales taxes.

```{r}
#| label: tbl-tax-ev-deconv-moments
#| tbl-cap: Average tax evasion by Industry. Estimates show the average tax evasion from the output shock in @eq-ob-ev.  LCI and UCI are the bias-corrected bootsrap confidence intervals at the 10\% significance level with 250 bootstrap replicates. Intermediates are defined as raw materials. 

load("../Code/Products/boot_tax_ev_mmt.RData")

tax_ev_boot_tbl_90 %>%
  filter( 
    # inter == "log_mats_share",
    # sic_3 %in% top_5_ev_inds
  ) %>%
  mutate(
    inter = factor(inter, 
      levels = c("log_mats_share","log_deductible_intermediates_share"), 
      labels = c("Materials","Deductibles"))#,
    # sic_3 = factor(sic_3,levels=top_5_ev_inds)
  ) %>%
  arrange(sic_3) %>%
  select(SIC=sic_3, Inter=inter,Mean=mu, LCI, UCI) %>%
  # slice(1:5) %>%
  kbl(
    # col.names = c("SIC","Mean", "LCI", "UCI"),
    digits = 4,
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(full_width=F, html_font = "Cambria") %>%
  collapse_rows(columns = 1, valign = "top")

```

<!-- @fig-deconv-mmt presents the results of the first and second moments of tax evasion for the top ten industries with the highest rates of cost overreporting for different measures of inputs. Intermediates include materials, deductible and non-deductible expenses. Deductibles include materials and deductible expenses, while materials only include raw materials. -->

```{r}
#| label: fig-deconv-mmt
#| fig-cap: First and second moments of deconvoluting tax evasion from the output shock. The second moment is included in the form of the 95% confidence interval. The absolute value of the variance was used in estimating the confidence intervals because some variances were negative.
#| eval: false

load("../Code/Products/deconv.RData")

order_sic<-deconv_mmt_long%>%
    group_by(sic_3) %>%
    summarise(highest_mean=max(mean)) %>%
    arrange(desc(highest_mean)) %>%
    pull(sic_3)
deconv_mmt_long%>%
    filter( sic_3 %in% order_sic[1:10]) %>% #Only top 10 Evasion Industries
    ggplot(aes(x=factor(sic_3, levels = order_sic), y=mean, group=share,color=share, fill=share))+
    geom_point()+
    geom_errorbar(aes(ymin=LCI, ymax=UCI)) +
    geom_hline(yintercept = 0, linetype = "dashed", linewidth=0.5) +
    coord_flip() +
    labs(x="Industry", y="Mean Evasion", title = "Mean Evasion by Industry") +
    theme_classic()+
    theme(legend.position = c(0.95, 0.95), legend.justification = c(1, 1), legend.title = element_blank())

```

<!-- Overall, deductible expenses and materials display a higher logmean cost overreporting than when looking at intermediate inputs. This implies that altough the logshare of intermediates might be closer or even lower than non-evading firms, evading firms report a higher share of deductible expenses. Depending on the industry, firms might overreport either materials or other deductible expenses to evade taxes. -->

The top five tax evading industries, 322 (Wearing Apparel), 342 (Publishing), 313 (Beverages), 351 (Industrial Chemicals), and 331 (Wood Products), display an average tax evasion $e$ greater than 12%, which is non-trivial.

Although deconvolution by moments is the simplest method, it displays the undesirable characteristic that estimate of variances frequently result with a negative sign. In the next section, I address this problem by using parametric MLE. 

### Deconvoluting by Parametric MLE

I use parametric MLE to obtain better estimates of the variances using equation @eq-mle. I assume that the error term $\varepsilon$ follows a normal distribution. 


<!-- 
```{r}
#| label: tbl-deconv-mle
#| tbl-cap: Estimates of the first and second moments of the evasion distribution using a parametric MLE approach assuming a Normal distribution.
#| eval: false

load("../Code/Products/deconv_mle.RData")

sapply(
  names(norm_res_list),
  \(x)norm_res_list[[x]]$ev_params
  ) |> 
  t() %>%
  kbl(
    digits = 4,
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(full_width=F, html_font = "Cambria")


``` 
-->

<!-- In @tbl-deconv-mle, the means coincide with the previous estimates using moments, but now the variances are positive. The corresponding confindence intervals suggest that using the absolute value of the variances obtained using moments is not unreasonable and in fact they are good approximations. -->

<!-- For tax-evasion, I first use a log-normal distribution restricting variances to be positive and compare to the previous estimates using moments. The estimates are shown in @tbl-deconv-mle -->

For tax-evasion, theory suggests that firms only have incentives to overreport costs, not to underreport them. Therefore, as explained elsewhere, it might be expected that overreporting $e\ge0$ is non-negative. In addition, it might also be expected that most firms overreport a little and a few firms overreport greater amounts. Therefore, a lognormal or a truncated normal distribution might be more appropriate.

<!-- @tbl-deconv-mle-lognormal displays the results of a parametric MLE using a lognormal distribution for the evasion random variable. -->

By definition, if a random variable $U$ is log-normal distributed, then $log(U)\sim N(\mu, \sigma)$. Thus, we cannot directly compare the parameters of the log-normal distribution to our previous estimates. We can however, used the parameters to compute any moment of the log-normally distributed variable $U$ by

$$
E[U^n]=e^{n\mu+\frac{1}{2}n^2\sigma^2}
$$

In particular, the first moment and the variance are computed as follows,

$$
\begin{aligned}  
E[U]&=e^{\mu+\frac{1}{2}\sigma^2}\\
Var[U]&=E[U^2]-E[U]^2=e^{2\mu+\sigma^2}(e^{\sigma^2}-1).
\end{aligned}
$$


In addition, the mode and the mean by

$$
\begin{aligned}
  \text{Mode}[U]&=e^{\mu-\sigma^2} \\
  \text{Med}[U]&=e^{\mu}
\end{aligned}
$$

<!-- 

To compute the confidence intervals for the mean, one practical method to approximate them is the Cox method,

$$
CI(E[U]): e^{\left(\mu+\frac{1}{2}\sigma^2 \pm z_{1-\frac{\alpha}{2}}\sqrt{\frac{\sigma^2}{N}+\frac{\sigma^4}{2(N-1)}}\right)}
$$ 

-->


<!-- @tbl-deconv-mle displays the mean, variance, mode, median and the approximated 95% CI intervals for the mean using the Cox method. -->

<!-- 
```{r}
#| label: tbl-deconv-mle-lognormal
#| tbl-cap: Estimates of the first and second moments of the evasion distribution using a parametric MLE approach assuming a Log-Normal distribution.
#| eval: false

sapply(
  names(lognorm_res_list),
  \(x)lognorm_res_list[[x]]$ev_params
  )[-c(1,2),] |> 
  t()  %>%
  kbl(
    digits = 4,
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(full_width=F, html_font = "Cambria")

```
 
 -->

Likewise, the probability density function of random variable $U$ with a normal distribution with parameters $\tilde\mu$ and $\tilde\sigma$ and truncated from below at zero is

$$
  f(u\\;\tilde\mu,\tilde\sigma) = \frac{\varphi(\frac{u-\tilde\mu}{\tilde\sigma})}{\tilde\sigma (1-\Phi(\alpha))}
$$


where 

$$
\varphi(\xi)=\frac{1}{2\pi}\exp(-\frac{1}{2}\xi^2)
$$

is the probability density function of the standard normal distribution, $\Phi(\centerdot)$ is its cumulative distribution function, and $\alpha=-\tilde\mu/\tilde\sigma$

Then, the mean becomes

$$
E[U|U>0]=\tilde\mu+\tilde\sigma\frac{\varphi(\alpha)}{1-\Phi(\alpha)}
$$

and the variance, median, and mode become

$$
\begin{aligned}  
Var[U|U>0]&=\sigma^2[1+\alpha\varphi(\alpha)/(1-\Phi(\alpha))-(\varphi(\alpha)/[1-\Phi(\alpha)])^2]\\
\text{Median}[U|U>0]&=\tilde\mu+\Phi^{-1}\left(\frac{\Phi(\alpha)+1}{2}\right)\tilde\sigma \\ 
\text{Mode}[U|U>0]&=\tilde\mu
\end{aligned}
$$



@tbl-deconv-mle-both displays the estimates of the parameters for both the log-normal and truncated normal distributions using an MLE approach. Other moments of the densities are computed as explained previously and shown for reference.

```{r}
#| label: tbl-deconv-mle-both
#| tbl-cap: Estimates of Deconvoluting Tax Evasion from the Output Shock in @eq-ob-ev by Parametric MLE Using A Log-Normal and a Truncated-Normal Distribution. $\mu$ and $\sigma$ are the parameters of the densities. Moments displayed are estimated using the distribution paramters as explained above. Intermediates are defined as raw materials.

load("../Code/Products/boot_deconv_mle.RData")

mle_deconv_tbl %>%
  filter(
    inter == "materials", #deductible_intermediates",
    sic_3 %in% top_5_ev_inds #top_10_revenue$sic_3[1:5]
  ) %>%
  select(
    sic_3, dist, mu:median
  ) %>%
  mutate(
    across(
      mu:median,
      ~ round(as.numeric(.x),4)
    )
  ) %>%
  group_by(sic_3,dist) %>%
  arrange(dist, .by_group = TRUE) %>%
  # slice(1:10) %>%
  kable(
    digits = 4,
    # col.names = c("SIC","Density","$\\mu$","$\\sigma$","Mean","SD","Mode","Median"),
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  kable_classic(full_width=F, html_font = "Cambria")%>%
  collapse_rows(columns = 1, valign = "top")

```

Both the log-normal and the truncated normal distributions point to similar means. The differences between the other moments of the distributions can be explained by the differences in the shapes of their probability density functions. The standard deviation is larger in the log-normal distribution than in the truncated normal distribution which can be explained by the asymmetry of the log normal distribution which is skewed to the right. With respect to the mode, it is the same to the mean in the case of the truncated normal distribution, while it is lower than the median for the log-normal. Finally, the median is lower than the mean in the case of the log-normal, but higher than the mean in the case of the truncated normal because of the truncation from below.

Both distributions show higher estimates of the average overreporting in logs than using only moments. Now it looks like firms evade taxes by inflating their cost of their materials by 40 percent or more. 

@tbl-deconv-mle-boot shows the bias corrected bootstrap confidence intervals for the mean of each distribution by industry using 200 replicates. 


```{r}
#| label: tbl-deconv-mle-boot
#| tbl-cap: Estimates of Deconvoluting Tax Evasion from the Output Shock in @eq-ob-ev by Parametric MLE Using A Log-Normal and a Truncated-Normal Distribution. LCI and UCI are the bias corrected bootstrap confidence intervals at the 5 percent significance level using 250 replicates.

# load("../Code/Products/boot_deconv_mle.RData")

# boot_mle_deconv_tbl %>%
#   mutate(
#     across(
#       !c(SIC,Distribution),
#       ~round(.x,4)
#     ),
#     Mean = glue::glue("{mean} [{CI_mean_LCI}, {CI_mean_UCI}]"),
#     SD = glue::glue("{sd} [{CI_sd_LCI}, {CI_sd_UCI}]")
#   ) %>%
#   select(SIC,Density=Distribution,Mean, SD) %>%
#   kable(
#     # col.names = c("SIC","Density","Mean","[","]")
#     digits = 4,
#     table.attr = 'data-quarto-disable-processing="true"'
#   ) %>%
#   kable_classic(full_width=F, html_font = "Cambria") %>%
#   collapse_rows(columns = 1, valign = "top")


boot_tx_ev_mle_tbl %>%
  ungroup() %>%
  filter( 
    inter == "materials", #deductible_intermediates",
    sic_3 %in% top_5_ev_inds
  ) %>%
  select(
    SIC = sic_3,
    Density = dist,
    Mean = mean,
    SD = sd
  ) %>%
  # slice(1:20) %>%
  kable(
    # col.names = c("SIC","Density","Mean","[","]")
    digits = 4,
    table.attr = 'data-quarto-disable-processing="true"'
  ) %>%
  collapse_rows(columns = 1:2, valign = "top") %>%
  kable_classic(full_width=F, html_font = "Cambria")

  
```


The difference between our previous estimates using moments can be explained by the fact that the log-normal and truncated distribution are restricted to positive values while we did not apply the restriction when using moments. Were we to take the average of only the positive values, the mean of the moments' method would be higher and closer to the log-normal and truncated normal distributions. 

From the perspective of theory, firms would have incentives to overreport their materials. Therefore, using moments to estimate overreporting without restricting to positive values like in the case of the MLE method using a log-normal or truncated distribution might underestimate tax evasion through cost overreporting. 


::: {#fig-density-plots layout-ncol="1"}

```{r}
#| warning: false
#| error: false
#| eval: true
#| cache: true

library(truncnorm)

density_plots<-lapply(
    top_5_ev_inds,
    function(i){

      if (i==322){
        x<-seq(0,2,by=0.01)
      } else {
        x<-seq(0,1.5,by=0.01) 
      }


        mu<-mle_deconv_tbl %>% 
            filter(
              sic_3==i, dist=="lognormal",
              inter == "materials"
            ) %>%
            pull(mu)  |> as.numeric()
        sigma<-mle_deconv_tbl %>% 
            filter(
              sic_3==i, dist=="lognormal",
              inter == "materials"
            ) %>%
            pull(sigma) |> as.numeric()
        mu2<-mle_deconv_tbl %>% 
            filter(
              sic_3==i, dist=="truncated normal",
              inter == "materials"
            ) %>%
            pull(mu) |> as.numeric()
        sigma2<-mle_deconv_tbl %>% 
            filter(
              sic_3==i, dist=="truncated normal",
              inter == "materials"
            ) %>%
            pull(sigma) |> as.numeric()

        plot(
            x,
            dtruncnorm(x,a=0,mean=mu2,sd=sigma2),
            type = "l", col="red",
                    xlab = "", ylab = "",
            main = paste(
                i,
                str_sub(
                    paste0(
                        top_20_inds[top_20_inds$sic_3==i,'description'][[1]]
                    ),
                    1,30
                ),
                "..."
            )
        )
        lines(
            x,
            dlnorm(x,mu,sigma),
            type = "l", col="blue"
        )
    }
)


par(mfrow = c(5, 1)) # Establecer la disposición de la cuadrícula

for (plot in density_plots) {
   print(plot)
}

par(mfrow = c(1, 1))

```

Truncated Normal (red) and Log-Normal (blue) distribution of the overreporting of raw materials for the top tax-evading industries.

:::


<!-- ### By Year -->

```{r}
#| label: fig-deconv-mmt-year
#| fig-cap: First and second moments of deconvoluting tax evasion from the output shock by industry and year. The second moment is included in the form of the 95% confidence interval. The absolute value of the variance was used in estimating the confidence intervals because some variances were negative.
#| eval: false


load("../Code/Products/deconv_year.RData")

plots_year<-lapply(top_evading_inds[1:6],\(x)
    deconv_mmt_long_y%>%
        filter(sic_3==x) %>%
        ggplot(aes(x=factor(year), y=mean, group=share,color=share, fill=share))+
        geom_line()+
        geom_errorbar(aes(ymin=LCI, ymax=UCI)) +
        geom_vline(xintercept = "83", linetype = "dashed", linewidth=0.5) +
        # coord_flip() +
        labs(x="Year", y="Mean Evasion", title = "Mean Evasion by Year", subtitle = evasion_inds_description[[paste0(x)]]) +
        theme_classic()+
        theme(legend.position = "top", legend.justification = c(1, 1), legend.title = element_blank())
)

par(mfrow = c(6, 1)) # Establecer la disposición de la cuadrícula

for (plot in plots_year) {
  print(plot)
}

# Restablecer la disposición de la cuadrícula a la configuración predeterminada
par(mfrow = c(1, 1))

```

### Non-Parametric Deconvolution using Penalized B-Splines

```{r}
#| label: tbl-np-deconv
#| tbl-cap: Semiparametric Deconvolution of Tax Evasion using Penalized B-Splines. I used a kernel density estimator to fit the error density on the residuals of the first stage conditional on firms being Non-Evaders.

load("../Code/Products/bs_mle_data.Rdata")


np_stats_df %>%
  mutate(
    sic_3 = stringr::str_extract(rownames(.),"\\d{3}"),
    .before = mean
  ) %>%
  kbl(
    digits = 3,
    table.attr = 'data-quarto-disable-processing="true"',
    row.names = FALSE
  ) %>%
  kable_classic(full_width=F, html_font = "Cambria")



```